{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": []}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}, "widgets": {"application/vnd.jupyter.widget-state+json": {"71c2498537e44a36bf733b45d4c0739b": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_e8dba302dc75434898075ad3280c8b22", "IPY_MODEL_82b08cb32b13486f97d02d5a234b2fe1", "IPY_MODEL_3d21e9b22e434a3a9548cbe10356c500"], "layout": "IPY_MODEL_0b2e05e1d9ba46e3b506936f2b64c636"}}, "e8dba302dc75434898075ad3280c8b22": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_6155dc3646f142d8b470d4e3b885c547", "placeholder": "\u200b", "style": "IPY_MODEL_be01e199edb54b3eb55491161df01d84", "value": "tokenizer_config.json:\u2027100%"}}, "82b08cb32b13486f97d02d5a234b2fe1": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_cad476a6d95f4e78bc832032dcb51b3d", "max": 26, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_cc85cc24074d4788b65da78b56be1d4e", "value": 26}}, "3d21e9b22e434a3a9548cbe10356c500": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_c7e3c50993d841e69cef4c6de3637af7", "placeholder": "\u200b", "style": "IPY_MODEL_fe50f96ec7b94123b99488fde0850435", "value": "\u200726.0/26.0\u200b[00:00<00:00,\u200b590B/s]"}}, "0b2e05e1d9ba46e3b506936f2b64c636": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}}}}, "cells": [{"cell_type": "code", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "8e1abcde", "outputId": "f369d2c7-4da0-43fb-9d04-0584ef6d19c4"}, "source": ["#Import libraries\n", "import pandas as pd\n", "import numpy as np\n", "import re\n", "import string\n", "from collections import Counter, defaultdict\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from tqdm import tqdm\n", "import torch\n", "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling\n", "from transformers import Trainer, TrainingArguments\n", "import nltk\n", "from nltk.corpus import words\n", "from nltk.tokenize import word_tokenize\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "# Download NLTK data\n", "nltk.download('punkt')\n", "nltk.download('words')\n", "nltk.download('averaged_perceptron_tagger')\n", "\n", "print(\"✓ All libraries imported successfully!\")\n"], "execution_count": null, "outputs": [{"output_type": "stream", "name": "stderr", "text": ["[nltk_data] Downloading package punkt to /root/nltk_data...\n", "[nltk_data]   Unzipping tokenizers/punkt.zip.\n", "[nltk_data] Downloading package words to /root/nltk_data...\n", "[nltk_data]   Unzipping corpora/words.zip.\n", "[nltk_data] Downloading package averaged_perceptron_tagger to\n", "[nltk_data]     /root/nltk_data...\n", "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}, {"output_type": "stream", "name": "stdout", "text": ["✓ All libraries imported successfully!\n"]}]}, {"cell_type": "markdown", "source": ["# **STEP 2: LOAD AND EXPLORE DATASETS**"], "metadata": {"id": "uYmOyITN-aUQ"}}, {"cell_type": "code", "source": ["conversation_df = pd.read_csv('/Conversation.csv')\n", "quotes_df = pd.read_csv('/train (1).csv')\n", "\n", "print(\"Dataset Information:\")\n", "print(f\\"\\nConversation Dataset Shape: {conversation_df.shape}\\")\n", "print(conversation_df.head())\n", "print(f\\"\\nQuotes Dataset Shape: {quotes_df.shape}\\")\n", "print(quotes_df.head())\n", "\n", "# Combine all text data\n", "all_text = []\n", "all_text.extend(conversation_df['question'].dropna().tolist())\n", "all_text.extend(conversation_df['answer'].dropna().tolist())\n", "all_text.extend(quotes_df['Quotes'].dropna().tolist())\n", "\n", "print(f\\"\\nTotal text samples: {len(all_text)}\\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "yOlIanMONL3q", "outputId": "63c5b16f-38b4-4243-840b-594941ca6284"}, "execution_count": null, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Dataset Information:\n", "\n", "Conversation Dataset Shape: (3725, 3)\n", "   Unnamed: 0                             question  \\n", "0           0               hi, how are you doing?  \\n", "1           1        i'm fine. how about yourself?  \\n", "2           2  i'm pretty good. thanks for asking.  \\n", "3           3    no problem. so how have you been?  \\n", "4           4     i've been great. what about you?  \\n", "\n", "                                     answer  \\n", "0             i'm fine. how about yourself?  \\n", "1       i'm pretty good. thanks for asking.  \\n", "2         no problem. so how have you been?  \\n", "3          i've been great. what about you?  \\n", "4  i've been good. i'm in school right now.  \\n", "\n", "Quotes Dataset Shape: (1000, 1)\n", "                                              Quotes\n", "0  Embrace the beauty of every sunrise; it's a fr...\n", "1  Embrace challenges; they are the stepping ston...\n", "2  Embrace the rhythm of life and let it dance th...\n", "3  Embrace kindness, for it has the power to chan...\n", "4  Embrace the journey, for it leads to the desti...\n", "\n", "Total text samples: 8450\n"]}]}, {"cell_type": "markdown", "source": ["# **STEP 3: DATA PREPROCESSING**"], "metadata": {"id": "RDKYkMJV_JQz"}}, {"cell_type": "code", "source": ["def preprocess_text(text):\n", "    \"\"\"Clean and preprocess text data\"\"\"\n", "    if pd.isna(text):\n", "        return \"\"\n", "    text = str(text).lower()\n", "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n", "    text = re.sub(r'\\s+', ' ', text)\n", "    text = text.strip()\n", "    return text\n", "\n", "# Preprocess all text\n", "processed_text = [preprocess_text(text) for text in all_text if text]\n", "processed_text = [text for text in processed_text if len(text) > 10]\n", "\n", "print(f\"Processed text samples: {len(processed_text)}\")\n", "print(f\"Sample: {processed_text[0][:100]}\")\n", "\n", "# Create a combined text file for training\n", "with open('training_data.txt', 'w', encoding='utf-8') as f:\n", "    for text in processed_text:\n", "        f.write(text + '\\n')\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "AbVi4kco_Jtm", "outputId": "1bb3ffa5-ea61-4389-fb29-19eae57f5beb"}, "execution_count": null, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Processed text samples: 8158\n", "Sample: hi, how are you doing?\n"]}]}, "...rest of notebook trimmed for brevity..."}